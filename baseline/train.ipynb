{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1ae602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== FAST Fine-tune: EfficientNetB3 / Xception với Augmentation khác nhau =====\n",
    "import os, time, random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score,accuracy_score\n",
    "\n",
    "# ---------- Model-specific Config (CHỈ ĐỔI AUGMENTATION) ----------\n",
    "CONFIG = {\n",
    "    \"xception\": {\n",
    "        \"augment\": \"basic\",      # Strong augmentation (RandAugment + RandomErasing)\n",
    "        \"lr\": 1e-4,\n",
    "        \"weight_decay\": 1e-4,\n",
    "    },\n",
    "    \"efficientnet_b3\": {\n",
    "        \"augment\": \"basic\",       # Basic augmentation (Crop + Flip)\n",
    "        \"lr\": 1e-4,\n",
    "        \"weight_decay\": 1e-4,\n",
    "        \"optimizer\": \"rmsprop\",  # Đặc biệt: dùng RMSProp cho EfficientNetB3\n",
    "        \"scheduler\": \"cosine\",   # Đặc biệt: dùng CosineAnnealingLR cho EfficientNetB3\n",
    "    },\n",
    "    \"resnet50\": {\n",
    "        \"augment\": \"basic\",       # Basic augmentation (Crop + Flip)\n",
    "        \"lr\": 1e-4,\n",
    "        \"weight_decay\": 1e-4,\n",
    "    }\n",
    "}\n",
    "\n",
    "# ---------- Params ----------\n",
    "DATASET_ROOT   = \"../Dataset\"\n",
    "MODEL_KEY      = \"xception\"                    # {\"efficientnet_b3\", \"xception\", \"resnet50\"}\n",
    "INPUT_SIZE     = 224\n",
    "BATCH_SIZE     = 64\n",
    "EPOCHS         = 10\n",
    "NUM_WORKERS    = min(8, os.cpu_count() or 4)\n",
    "USE_AMP_WISH   = True\n",
    "CHANNELS_LAST  = True\n",
    "MAX_TRAIN_SAMPLES_PER_EPOCH = 20000\n",
    "FREEZE_BACKBONE = True\n",
    "WARMUP_EPOCHS   = 2\n",
    "DROP_CONNECT   = 0.2\n",
    "DROPOUT        = 0.3\n",
    "DROP_RATE_XCP  = 0.2\n",
    "DROP_PATH_XCP  = 0.1\n",
    "\n",
    "# Lấy config cho model hiện tại\n",
    "cfg = CONFIG[MODEL_KEY.lower()]\n",
    "LR = cfg[\"lr\"]\n",
    "WEIGHT_DECAY = cfg[\"weight_decay\"]\n",
    "\n",
    "# ---------- Setup ----------\n",
    "def set_seed(s=42):\n",
    "    random.seed(s); np.random.seed(s); torch.manual_seed(s)\n",
    "    torch.cuda.manual_seed_all(s); torch.backends.cudnn.benchmark = True\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cc = torch.cuda.get_device_capability() if device.type==\"cuda\" else (0,0)\n",
    "USE_AMP = bool(USE_AMP_WISH and device.type==\"cuda\" and cc[0] >= 7)\n",
    "DATASET_ALIAS = Path(DATASET_ROOT).name\n",
    "if device.type==\"cuda\":\n",
    "    try: torch.set_float32_matmul_precision(\"high\")\n",
    "    except: pass\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)} | CC: {cc[0]}.{cc[1]} | AMP: {USE_AMP}\")\n",
    "\n",
    "print(f\"\\n[Model: {MODEL_KEY}]\")\n",
    "print(f\"Config: {cfg}\")\n",
    "\n",
    "# ---------- Data với Augmentation theo config ----------\n",
    "mean, std = [0.485,0.456,0.406], [0.229,0.224,0.225]\n",
    "eval_tfms = transforms.Compose([\n",
    "    transforms.Resize(int(INPUT_SIZE*1.15), interpolation=InterpolationMode.BILINEAR),\n",
    "    transforms.CenterCrop(INPUT_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "def build_train_transform(augment_type):\n",
    "    base_resize = transforms.Resize(int(INPUT_SIZE*1.15), interpolation=InterpolationMode.BILINEAR)\n",
    "    \n",
    "    if augment_type == \"strong\":\n",
    "        # Strong augmentation: RandAugment + RandomErasing\n",
    "        return transforms.Compose([\n",
    "            base_resize,\n",
    "            transforms.RandomCrop(INPUT_SIZE),\n",
    "            transforms.RandAugment(num_ops=2, magnitude=9),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std),\n",
    "            transforms.RandomErasing(p=0.25, scale=(0.02, 0.2)),\n",
    "        ])\n",
    "    else:  # basic\n",
    "        # Basic augmentation: Crop + Flip\n",
    "        return transforms.Compose([\n",
    "            base_resize,\n",
    "            transforms.RandomCrop(INPUT_SIZE),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std),\n",
    "        ])\n",
    "\n",
    "train_tfms = build_train_transform(cfg[\"augment\"])\n",
    "\n",
    "def make_loader(ds, shuffle, batch_size=BATCH_SIZE):\n",
    "    kwargs = dict(batch_size=batch_size, shuffle=shuffle,\n",
    "                  num_workers=NUM_WORKERS, pin_memory=(device.type==\"cuda\"))\n",
    "    if NUM_WORKERS > 0: kwargs.update(dict(persistent_workers=True, prefetch_factor=4))\n",
    "    return DataLoader(ds, **kwargs)\n",
    "\n",
    "# tạo dataset\n",
    "train_ds = datasets.ImageFolder(os.path.join(DATASET_ROOT, \"train\"), transform=train_tfms)\n",
    "val_ds   = datasets.ImageFolder(os.path.join(DATASET_ROOT, \"val\"),   transform=eval_tfms)\n",
    "test_ds  = datasets.ImageFolder(os.path.join(DATASET_ROOT, \"test\"),  transform=eval_tfms)\n",
    "print(f\"[train] {len(train_ds)} | [val] {len(val_ds)} | [test] {len(test_ds)} | classes={train_ds.classes}\")\n",
    "NUM_CLASSES = len(train_ds.classes)\n",
    "\n",
    "# ---------- Model ----------\n",
    "from my_efficientnet import EfficientNetB3\n",
    "from my_xception import Xception\n",
    "from my_resnet import ResNet50\n",
    "\n",
    "def build_model(key, num_classes):\n",
    "    k = key.lower()\n",
    "    if k == \"efficientnet_b3\":\n",
    "        m = EfficientNetB3(num_classes=num_classes,\n",
    "                           drop_connect_rate=DROP_CONNECT,\n",
    "                           dropout=DROPOUT,\n",
    "                           pretrained=True,\n",
    "                           freeze_backbone=FREEZE_BACKBONE)\n",
    "        name = \"efficientnet_b3\"\n",
    "    elif k == \"xception\":\n",
    "        m = Xception(num_classes=num_classes,\n",
    "                     drop_rate=DROP_RATE_XCP,\n",
    "                     drop_path_rate=DROP_PATH_XCP,\n",
    "                     pretrained=True,\n",
    "                     freeze_backbone=FREEZE_BACKBONE)\n",
    "        name = \"xception\"\n",
    "    elif k == \"resnet50\":\n",
    "        m = ResNet50(num_classes=num_classes,\n",
    "                     pretrained=True,\n",
    "                     freeze_backbone=FREEZE_BACKBONE)\n",
    "        name = \"resnet50\"\n",
    "    else:\n",
    "        raise ValueError(k)\n",
    "    return m, name\n",
    "\n",
    "model, model_name = build_model(MODEL_KEY, NUM_CLASSES)\n",
    "model = model.to(device, memory_format=torch.channels_last if CHANNELS_LAST else torch.contiguous_format)\n",
    "\n",
    "# ---------- Optimizer & Scheduler (GIỐNG NHAU cho cả 2 model) ----------\n",
    "if MODEL_KEY.lower() == \"efficientnet_b3\":\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY, momentum=0.9)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "    print(\"Optimizer: RMSProp | Scheduler: CosineAnnealingLR | Augment: basic\")\n",
    "else:\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "    print(f\"Optimizer: AdamW | Scheduler: CosineAnnealingLR | Augment: {cfg['augment']}\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = torch.amp.GradScaler('cuda', enabled=USE_AMP)\n",
    "\n",
    "# ---------- Train/Eval ----------\n",
    "def run_epoch(loader, train_mode=True):\n",
    "    model.train(train_mode)\n",
    "    tot, correct, loss_sum = 0, 0, 0.0\n",
    "    \n",
    "    for x,y in loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        if CHANNELS_LAST: x = x.to(memory_format=torch.channels_last)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "        with torch.set_grad_enabled(train_mode):\n",
    "            with torch.amp.autocast('cuda', enabled=scaler.is_enabled()):\n",
    "                logits = model(x); loss = criterion(logits, y)\n",
    "        if train_mode:\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            if scaler.is_enabled():\n",
    "                scaler.scale(loss).backward(); scaler.step(optimizer); scaler.update()\n",
    "            else:\n",
    "                loss.backward(); optimizer.step()\n",
    "        \n",
    "        preds = logits.argmax(1)\n",
    "        loss_sum += loss.item()*x.size(0)\n",
    "        correct += (preds==y).sum().item()\n",
    "        tot += x.size(0)\n",
    "    acc = correct/tot\n",
    "\n",
    "    return loss_sum/tot, acc\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    \"\"\"Evaluate model on test set with DataLoader\"\"\"\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device, non_blocking=True)\n",
    "            if CHANNELS_LAST:\n",
    "                x = x.to(memory_format=torch.channels_last)\n",
    "            y = y.to(device, non_blocking=True)\n",
    "            \n",
    "            with torch.amp.autocast('cuda', enabled=scaler.is_enabled()):\n",
    "                logits = model(x)\n",
    "            \n",
    "            preds = logits.argmax(1)\n",
    "            y_true.extend(y.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "    \n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average='weighted')\n",
    "    rec = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    return acc, prec, rec, f1\n",
    "\n",
    "# ---------- Loop ----------\n",
    "best_val = -1.0\n",
    "ckpt_path = f\"{model_name}_{DATASET_ALIAS}_best.pth\"\n",
    "val_loader = make_loader(val_ds, shuffle=False)\n",
    "test_loader = make_loader(test_ds, shuffle=False)\n",
    "\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    if FREEZE_BACKBONE and ep == WARMUP_EPOCHS+1 and hasattr(model, \"unfreeze\"):\n",
    "        model.unfreeze()\n",
    "\n",
    "    # chọn ngẫu nhiên N mẫu/epoch (nếu set)\n",
    "    if MAX_TRAIN_SAMPLES_PER_EPOCH and MAX_TRAIN_SAMPLES_PER_EPOCH < len(train_ds):\n",
    "        idx = np.random.permutation(len(train_ds))[:MAX_TRAIN_SAMPLES_PER_EPOCH]\n",
    "        train_sub = Subset(train_ds, idx)\n",
    "        train_loader = make_loader(train_sub, shuffle=True)\n",
    "        epoch_info = f\"{len(idx)}/{len(train_ds)} imgs\"\n",
    "    else:\n",
    "        train_loader = make_loader(train_ds, shuffle=True)\n",
    "        epoch_info = f\"{len(train_ds)} imgs\"\n",
    "\n",
    "    t0 = time.time()\n",
    "    tr_loss, tr_acc = run_epoch(train_loader, True)\n",
    "    val_loss, val_acc = run_epoch(val_loader, False)\n",
    "    scheduler.step()\n",
    "\n",
    "    if val_acc > best_val:\n",
    "        best_val = val_acc\n",
    "        torch.save({\"model\": model.state_dict(),\n",
    "                    \"epoch\": ep,\n",
    "                    \"val_acc\": best_val,\n",
    "                    \"model_name\": model_name,\n",
    "                    \"dataset_alias\": DATASET_ALIAS,\n",
    "                    \"input_size\": INPUT_SIZE,\n",
    "                    \"config\": cfg}, ckpt_path)\n",
    "\n",
    "    curr_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Epoch {ep:02d} [{epoch_info}] | \"\n",
    "          f\"train {tr_loss:.4f}/{tr_acc:.4f} | \"\n",
    "          f\"val {val_loss:.4f}/{val_acc:.4f} | \"\n",
    "          f\"best {best_val:.4f} | lr {curr_lr:.2e} | time {time.time()-t0:.1f}s\")\n",
    "\n",
    "print(f\"\\nSaved: {ckpt_path}\")\n",
    "\n",
    "# ---------- Test với checkpoint đã lưu ----------\n",
    "print(\"\\nLoading best checkpoint for testing...\")\n",
    "checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "model.load_state_dict(checkpoint[\"model\"])\n",
    "print(\"Model loaded!\")\n",
    "\n",
    "# Đo thời gian test\n",
    "test_start_time = time.time()\n",
    "test_acc, test_prec, test_rec, test_f1 = evaluate(model, test_loader)\n",
    "test_time = time.time() - test_start_time\n",
    "\n",
    "# Hiển thị kết quả với thời gian\n",
    "print(f\"\\nTEST RESULTS:\")\n",
    "print(f\"Accuracy:  {test_acc:.4f}\")\n",
    "print(f\"Precision: {test_prec:.4f}\")\n",
    "print(f\"Recall:    {test_rec:.4f}\")\n",
    "print(f\"F1-Score:  {test_f1:.4f}\")\n",
    "print(f\"Time:     {test_time:.2f}s ({len(test_ds)/test_time:.1f} imgs/s)\")\n",
    "\n",
    "# Cập nhật checkpoint với test metrics\n",
    "checkpoint['test_acc'] = test_acc\n",
    "checkpoint['test_precision'] = test_prec\n",
    "checkpoint['test_recall'] = test_rec\n",
    "checkpoint['test_f1'] = test_f1\n",
    "checkpoint['test_time'] = test_time\n",
    "torch.save(checkpoint, ckpt_path)\n",
    "print(f\"\\nUpdated {ckpt_path} with test metrics\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
