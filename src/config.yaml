# =========================
# Deep Feature Stacking + Meta-MLP
# =========================

project:
  name: deepfake_meta_learning
  seed: 42
  out_dir: outputs            # nơi lưu logs, mô hình, features đã trích
  save_path: meta_mlp_best.pth

device:
  use_amp: true               # dùng autocast/GradScaler khi có CUDA
  prefer_gpu: true            # nếu không có CUDA sẽ fallback CPU

data:
  dataset_root: ../Dataset       # Dataset/{train,val,test}/{class...}
  input_size: 224
  batch_size_img: 64
  num_workers: 8              # sẽ tự min(8, os.cpu_count()) trong code nếu cần
  normalize:
    mean: [0.485, 0.456, 0.406]
    std:  [0.229, 0.224, 0.225]

backbones:
  - name: xception
    pretrained: true
    global_pool: avg
  - name: efficientnet_b3
    pretrained: true
    global_pool: avg
  # nếu muốn b7 theo paper, đổi efficientnet_b3 -> efficientnet_b7 và input_size phù hợp (p=600+)

feature_selection:
  keep_frac: 0.5              # giữ top 50% đặc trưng (theo paper cho hiệu năng tốt)
  subsample: 100000           # số mẫu tối đa khi fit bộ chọn đặc trưng
  rankers:                    # average điểm/importance giữa các bộ chọn
    xgboost:
      enabled: true
      # tự động chọn GPU nếu có CUDA, ngược lại dùng 'hist'
      tree_method: auto       # 'gpu_hist' | 'hist' | 'auto' (auto = code tự chuyển theo CUDA)
      n_estimators: 300
      max_depth: 8
      learning_rate: 0.1
      subsample: 0.8
      colsample_bytree: 0.8
      n_jobs: 8
      random_state: 42
    random_forest:
      enabled: true
      n_estimators: 500
      max_depth: null
      n_jobs: 8
      random_state: 42

meta_mlp:
  epochs: 50
  batch_size: 32
  lr: 1.0e-3
  weight_decay: 1.0e-4
  dropout: 0.2
  epoch_sample: 20000         # số mẫu rút stratified mỗi epoch; null = dùng hết
  stratified_epoch_sample: true

logging:
  print_every: 1
  save_best_only: true
  eval_on_test_after_train: true
